{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1828d1ff-145a-4ce7-ad1f-adbcf06e0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "class Line:\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "        # Set the width of the windows +/- margin\n",
    "        self.window_margin = 56\n",
    "        # x values of the fitted line over the last n iterations\n",
    "        self.prevx = []\n",
    "        # polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]\n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None\n",
    "        # starting x_value\n",
    "        self.startx = None\n",
    "        # ending x_value\n",
    "        self.endx = None\n",
    "        # x values for detected line pixels\n",
    "        self.allx = None\n",
    "        # y values for detected line pixels\n",
    "        self.ally = None\n",
    "        # road information\n",
    "        self.road_inf = None\n",
    "        self.curvature = None\n",
    "        self.deviation = None\n",
    "\n",
    "def warp_image(img, src, dst, size):\n",
    "    \"\"\" Perspective Transform \"\"\"\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warp_img = cv2.warpPerspective(img, M, size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warp_img, M, Minv\n",
    "\n",
    "def rad_of_curvature(left_line, right_line):\n",
    "    \"\"\" measure radius of curvature  \"\"\"\n",
    "\n",
    "    ploty = left_line.ally\n",
    "    leftx, rightx = left_line.allx, right_line.allx\n",
    "\n",
    "    leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    width_lanes = abs(right_line.startx - left_line.startx)+1\n",
    "    ym_per_pix = 30 / 720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7*(720/1280) / width_lanes  # meters per pixel in x dimension\n",
    "\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
    "        2 * left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
    "        2 * right_fit_cr[0])\n",
    "    # radius of curvature result\n",
    "    left_line.radius_of_curvature = left_curverad\n",
    "    right_line.radius_of_curvature = right_curverad\n",
    "\n",
    "def smoothing(lines, pre_lines=3):\n",
    "    # collect lines & print average line\n",
    "    lines = np.squeeze(lines)\n",
    "    avg_line = np.zeros((720))\n",
    "\n",
    "    for ii, line in enumerate(reversed(lines)):\n",
    "        if ii == pre_lines:\n",
    "            break\n",
    "        avg_line += line\n",
    "    avg_line = avg_line / pre_lines\n",
    "\n",
    "    return avg_line\n",
    "\n",
    "def blind_search(b_img, left_line, right_line):\n",
    "    \"\"\"\n",
    "    blind search - first frame, lost lane lines\n",
    "    using histogram & sliding window\n",
    "    \"\"\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(b_img[int(b_img.shape[0] / 2):, :], axis=0)\n",
    "    \n",
    "   \n",
    "\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    output = np.dstack((b_img, b_img, b_img)) * 255\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0] / 2)\n",
    "    \n",
    "    \n",
    "    start_leftX = np.argmax(histogram[:midpoint])\n",
    "    start_rightX = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    num_windows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(b_img.shape[0] / num_windows)\n",
    "\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = b_img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Current positions to be updated for each window\n",
    "    current_leftX = start_leftX\n",
    "    current_rightX = start_rightX\n",
    "\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    min_num_pixel = 50\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    win_left_lane = []\n",
    "    win_right_lane = []\n",
    "\n",
    "    window_margin = left_line.window_margin\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(num_windows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = b_img.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = b_img.shape[0] - window * window_height\n",
    "        win_leftx_min = current_leftX - window_margin\n",
    "        win_leftx_max = current_leftX + window_margin\n",
    "        win_rightx_min = current_rightX - window_margin\n",
    "        win_rightx_max = current_rightX + window_margin\n",
    "\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(output, (win_leftx_min, win_y_low), (win_leftx_max, win_y_high), (0, 255, 0), 2)\n",
    "        cv2.rectangle(output, (win_rightx_min, win_y_low), (win_rightx_max, win_y_high), (0, 255, 0), 2)\n",
    "\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        left_window_inds = ((nonzeroy >= win_y_low) & (nonzeroy <= win_y_high) & (nonzerox >= win_leftx_min) & (\n",
    "            nonzerox <= win_leftx_max)).nonzero()[0]\n",
    "        right_window_inds = ((nonzeroy >= win_y_low) & (nonzeroy <= win_y_high) & (nonzerox >= win_rightx_min) & (\n",
    "            nonzerox <= win_rightx_max)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        win_left_lane.append(left_window_inds)\n",
    "        win_right_lane.append(right_window_inds)\n",
    "\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(left_window_inds) > min_num_pixel:\n",
    "            current_leftX = np.int(np.mean(nonzerox[left_window_inds]))\n",
    "        if len(right_window_inds) > min_num_pixel:\n",
    "            current_rightX = np.int(np.mean(nonzerox[right_window_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    win_left_lane = np.concatenate(win_left_lane)\n",
    "    win_right_lane = np.concatenate(win_right_lane)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx, lefty = nonzerox[win_left_lane], nonzeroy[win_left_lane]\n",
    "    rightx, righty = nonzerox[win_right_lane], nonzeroy[win_right_lane]\n",
    "\n",
    "    output[lefty, leftx] = [255, 0, 0]\n",
    "    output[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    left_line.current_fit = left_fit\n",
    "    right_line.current_fit = right_fit\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, b_img.shape[0] - 1, b_img.shape[0])\n",
    "\n",
    "    # ax^2 + bx + c\n",
    "    left_plotx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_plotx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "    left_line.prevx.append(left_plotx)\n",
    "    right_line.prevx.append(right_plotx)\n",
    "\n",
    "    if len(left_line.prevx) > 10:\n",
    "        left_avg_line = smoothing(left_line.prevx, 10)\n",
    "        left_avg_fit = np.polyfit(ploty, left_avg_line, 2)\n",
    "        left_fit_plotx = left_avg_fit[0] * ploty ** 2 + left_avg_fit[1] * ploty + left_avg_fit[2]\n",
    "        left_line.current_fit = left_avg_fit\n",
    "        left_line.allx, left_line.ally = left_fit_plotx, ploty\n",
    "    else:\n",
    "        left_line.current_fit = left_fit\n",
    "        left_line.allx, left_line.ally = left_plotx, ploty\n",
    "\n",
    "    if len(right_line.prevx) > 10:\n",
    "        right_avg_line = smoothing(right_line.prevx, 10)\n",
    "        right_avg_fit = np.polyfit(ploty, right_avg_line, 2)\n",
    "        right_fit_plotx = right_avg_fit[0] * ploty ** 2 + right_avg_fit[1] * ploty + right_avg_fit[2]\n",
    "        right_line.current_fit = right_avg_fit\n",
    "        right_line.allx, right_line.ally = right_fit_plotx, ploty\n",
    "    else:\n",
    "        right_line.current_fit = right_fit\n",
    "        right_line.allx, right_line.ally = right_plotx, ploty\n",
    "\n",
    "    left_line.startx, right_line.startx = left_line.allx[len(left_line.allx)-1], right_line.allx[len(right_line.allx)-1]\n",
    "    left_line.endx, right_line.endx = left_line.allx[0], right_line.allx[0]\n",
    "\n",
    "    #left_line.detected, right_line.detected = True, True\n",
    "    # print radius of curvature\n",
    "    rad_of_curvature(left_line, right_line)\n",
    "    return output\n",
    "\n",
    "\n",
    "def find_LR_lines(binary_img, left_line, right_line):\n",
    "    \"\"\"\n",
    "    find left, right lines & isolate left, right lines\n",
    "    blind search - first frame, lost lane lines\n",
    "    previous window - after detecting lane lines in previous frame\n",
    "    \"\"\"\n",
    "\n",
    "    # if don't have lane lines info\n",
    "    if left_line.detected == False:\n",
    "        return blind_search(binary_img, left_line, right_line)\n",
    "\n",
    "def draw_lane(img, left_line, right_line, lane_color=(255, 0,255), road_color=(50, 255,50)):\n",
    "    \"\"\" draw lane lines & current driving space \"\"\"\n",
    "    window_img = np.zeros_like(img)\n",
    "\n",
    "    window_margin = left_line.window_margin\n",
    "    left_plotx, right_plotx = left_line.allx, right_line.allx\n",
    "    ploty = left_line.ally\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_pts_l = np.array([np.transpose(np.vstack([left_plotx - window_margin/5, ploty]))])\n",
    "    left_pts_r = np.array([np.flipud(np.transpose(np.vstack([left_plotx + window_margin/5, ploty])))])\n",
    "    left_pts = np.hstack((left_pts_l, left_pts_r))\n",
    "    right_pts_l = np.array([np.transpose(np.vstack([right_plotx - window_margin/5, ploty]))])\n",
    "    right_pts_r = np.array([np.flipud(np.transpose(np.vstack([right_plotx + window_margin/5, ploty])))])\n",
    "    right_pts = np.hstack((right_pts_l, right_pts_r))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_pts]), lane_color)\n",
    "    cv2.fillPoly(window_img, np.int_([right_pts]), lane_color)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_plotx+window_margin/5, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_plotx-window_margin/5, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([pts]), road_color)\n",
    "    result = cv2.addWeighted(img, 1, window_img, 0.3, 0)\n",
    "\n",
    "    return result, window_img\n",
    "\n",
    "def road_info(left_line, right_line):\n",
    "    \"\"\" print road information onto result image \"\"\"\n",
    "    curvature = (left_line.radius_of_curvature + right_line.radius_of_curvature) / 2\n",
    "\n",
    "    direction = ((left_line.endx - left_line.startx) + (right_line.endx - right_line.startx)) / 2\n",
    "\n",
    "    if curvature > 2000 and abs(direction) < 100:\n",
    "        road_inf = 'No Curve'\n",
    "        curvature = -1\n",
    "    elif curvature <= 2000 and direction < - 50:\n",
    "        road_inf = 'Left Curve'\n",
    "    elif curvature <= 2000 and direction > 50:\n",
    "        road_inf = 'Right Curve'\n",
    "    else:\n",
    "        if left_line.road_inf != None:\n",
    "            road_inf = left_line.road_inf\n",
    "            curvature = left_line.curvature\n",
    "        else:\n",
    "            road_inf = 'None'\n",
    "            curvature = curvature\n",
    "\n",
    "    center_lane = (right_line.startx + left_line.startx) / 2\n",
    "    lane_width = abs(right_line.startx - left_line.startx)+1\n",
    "\n",
    "    center_car = 720 / 2\n",
    "    width_lanes = abs(right_line.startx - left_line.startx)+1\n",
    "    if center_lane > center_car:\n",
    "        deviation = 'Left ' + str(round(abs(center_lane - center_car)*3.7*(720/1280) / width_lanes, 3))+ 'm'\n",
    "    elif center_lane < center_car:\n",
    "        deviation = 'Right ' + str(round(abs(center_lane - center_car)*3.7*(720/1280) / width_lanes, 3)) + 'm'\n",
    "    else:\n",
    "        deviation = 'Center'\n",
    "    left_line.road_inf = road_inf\n",
    "    left_line.curvature = curvature\n",
    "    left_line.deviation = deviation\n",
    "\n",
    "    return road_inf, curvature, deviation\n",
    "\n",
    "def print_road_status(img, left_line, right_line):\n",
    "    \"\"\" print road status (curve direction, radius of curvature, deviation) \"\"\"\n",
    "    road_inf, curvature, deviation = road_info(left_line, right_line)\n",
    "    cv2.putText(img, 'Road Status', (22, 30), cv2.FONT_HERSHEY_COMPLEX, 0.7, (80, 80, 80), 2)\n",
    "\n",
    "    lane_inf = 'Lane Info : ' + road_inf\n",
    "    if curvature == -1:\n",
    "        lane_curve = 'Curvature : Straight line'\n",
    "    else:\n",
    "        lane_curve = 'Curvature : {0:0.3f}m'.format(curvature)\n",
    "    deviate = 'Deviation : ' + deviation\n",
    "\n",
    "    cv2.putText(img, lane_inf, (10, 63), cv2.FONT_HERSHEY_SIMPLEX, 0.50, (0, 0, 0), 1)\n",
    "    cv2.putText(img, lane_curve, (10, 83), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 0), 1)\n",
    "    cv2.putText(img, deviate, (10, 103), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 0), 1)\n",
    "\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d668b51-2109-4ba6-8450-9236cb0d1f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350f7c61-c24f-4458-bfa4-bd8f650a32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def sobel_xy(img, orient='x', thresh=(20, 100)):\n",
    "    \"\"\"\n",
    "    Define a function that applies Sobel x or y.\n",
    "    The gradient in the x-direction emphasizes edges closer to vertical.\n",
    "    The gradient in the y-direction emphasizes edges closer to horizontal.\n",
    "    \"\"\"\n",
    "\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 255\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \"\"\"\n",
    "    Define a function to return the magnitude of the gradient\n",
    "    for a given sobel kernel size and threshold values\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255\n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 255\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "def dir_thresh(img, sobel_kernel=3, thresh=(0.7, 1.3)):\n",
    "    \"\"\"\n",
    "    computes the direction of the gradient\n",
    "    \"\"\"\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction,\n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output = np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 255\n",
    "    # Return the binary image\n",
    "    return binary_output.astype(np.uint8)\n",
    "\n",
    "def ch_thresh(ch, thresh=(80, 255)):\n",
    "    binary = np.zeros_like(ch)\n",
    "    binary[(ch > thresh[0]) & (ch <= thresh[1])] = 255\n",
    "    return binary\n",
    "\n",
    "def gradient_combine(img, th_x, th_y, th_mag, th_dir):\n",
    "    \"\"\"\n",
    "    Find lane lines with gradient information of Red channel\n",
    "    \"\"\"\n",
    "    rows, cols = img.shape[:2]\n",
    "    R = img[220:rows - 12, 0:cols, 2]\n",
    "\n",
    "    sobelx = sobel_xy(R, 'x', th_x)\n",
    "    #cv2.imshow('sobel_x', sobelx)\n",
    "    sobely = sobel_xy(R, 'y', th_y)\n",
    "    #cv2.imshow('sobel_y', sobely)\n",
    "    mag_img = mag_thresh(R, 3, th_mag)\n",
    "    #cv2.imshow('sobel_mag', mag_img)\n",
    "    dir_img = dir_thresh(R, 15, th_dir)\n",
    "    #cv2.imshow('result5', dir_img)\n",
    "\n",
    "    # combine gradient measurements\n",
    "    gradient_comb = np.zeros_like(dir_img).astype(np.uint8)\n",
    "    gradient_comb[((sobelx > 1) & (mag_img > 1) & (dir_img > 1)) | ((sobelx > 1) & (sobely > 1))] = 255\n",
    "\n",
    "    return gradient_comb\n",
    "\n",
    "def hls_combine(img, th_h, th_l, th_s):\n",
    "    # convert to hls color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "    rows, cols = img.shape[:2]\n",
    "    R = img[220:rows - 12, 0:cols, 2]\n",
    "    _, R = cv2.threshold(R, 180, 255, cv2.THRESH_BINARY)\n",
    "    #cv2.imshow('red!!!',R)\n",
    "    H = hls[220:rows - 12, 0:cols, 0]\n",
    "    L = hls[220:rows - 12, 0:cols, 1]\n",
    "    S = hls[220:rows - 12, 0:cols, 2]\n",
    "\n",
    "    h_img = ch_thresh(H, th_h)\n",
    "    #cv2.imshow('HLS (H) threshold', h_img)\n",
    "    l_img = ch_thresh(L, th_l)\n",
    "    #cv2.imshow('HLS (L) threshold', l_img)\n",
    "    s_img = ch_thresh(S, th_s)\n",
    "    #cv2.imshow('HLS (S) threshold', s_img)\n",
    "\n",
    "    # Two cases - lane lines in shadow or not\n",
    "    hls_comb = np.zeros_like(s_img).astype(np.uint8)\n",
    "    hls_comb[((s_img > 1) & (l_img == 0)) | ((s_img == 0) & (h_img > 1) & (l_img > 1))] = 255 # | (R > 1)] = 255\n",
    "    #hls_comb[((s_img > 1) & (h_img > 1)) | (R > 1)] = 255\n",
    "    return hls_comb\n",
    "\n",
    "def comb_result(grad, hls):\n",
    "    \"\"\" give different value to distinguish them \"\"\"\n",
    "    result = np.zeros_like(hls).astype(np.uint8)\n",
    "    #result[((grad > 1) | (hls > 1))] = 255\n",
    "    result[(grad > 1)] = 100\n",
    "    result[(hls > 1)] = 255\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b50609d-ad9b-403e-a898-52611e9f4c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d164ba7-8986-4317-b6c3-4246825577e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "\n",
    "# Read in and make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Array to store object points and image points from all the images\n",
    "\n",
    "objpoints = []  # 3D points in real world space\n",
    "imgpoints = []  # 2D points in image plane\n",
    "\n",
    "def calib():\n",
    "    \"\"\"\n",
    "    To get an undistorted image, we need camera matrix & distortion coefficient\n",
    "    Calculate them with 9*6 20 chessboard images\n",
    "    \"\"\"\n",
    "    # Prepare object points\n",
    "    objp = np.zeros((6 * 9, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)  # x,y coordinates\n",
    "\n",
    "    for fname in images:\n",
    "\n",
    "        img = mpimg.imread(fname)\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "\n",
    "        # If corners are found, add object points, image points\n",
    "        if ret == True:\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    return mtx, dist\n",
    "\n",
    "def undistort(img, mtx, dist):\n",
    "    \"\"\" undistort image \"\"\"\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9e03d7-565a-482d-a9dc-74536d7d43ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdo\\AppData\\Local\\Temp\\ipykernel_16800\\2403868915.py:97: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  midpoint = np.int(histogram.shape[0] / 2)\n",
      "C:\\Users\\Abdo\\AppData\\Local\\Temp\\ipykernel_16800\\2403868915.py:106: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  window_height = np.int(b_img.shape[0] / num_windows)\n",
      "C:\\Users\\Abdo\\AppData\\Local\\Temp\\ipykernel_16800\\2403868915.py:151: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  current_leftX = np.int(np.mean(nonzerox[left_window_inds]))\n",
      "C:\\Users\\Abdo\\AppData\\Local\\Temp\\ipykernel_16800\\2403868915.py:153: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  current_rightX = np.int(np.mean(nonzerox[right_window_inds]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "input_type = 'video' #'video' # 'image'\n",
    "input_name = 'project_video.mp4' #'test_images/straight_lines1.jpg' # 'challenge_video.mp4'\n",
    "final=[]\n",
    "left_line = Line()\n",
    "right_line = Line()\n",
    "\n",
    "th_sobelx, th_sobely, th_mag, th_dir = (35, 100), (30, 255), (30, 255), (0.7, 1.3)\n",
    "th_h, th_l, th_s = (10, 100), (0, 60), (85, 255)\n",
    "\n",
    "# camera matrix & distortion coefficient\n",
    "mtx, dist = calib()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_type == 'video'\n",
    "    cap = cv2.VideoCapture(input_name)\n",
    "    \n",
    "    while (True):\n",
    "        \n",
    "        success, frame = cap.read()\n",
    "        if(success):\n",
    "\n",
    "             # Correcting for Distortion\n",
    "            undist_img = undistort(frame, mtx, dist)\n",
    "                # resize video\n",
    "            undist_img = cv2.resize(undist_img, None, fx=1 / 2, fy=1 / 2, interpolation=cv2.INTER_AREA)\n",
    "            rows, cols = undist_img.shape[:2]\n",
    "            \n",
    "            # gradient x + gradient y with sobel\n",
    "            combined_gradient = gradient_combine(undist_img, th_sobelx, th_sobely, th_mag, th_dir)\n",
    "            #cv2.imshow('gradient combined image', combined_gradient)\n",
    "           \n",
    "            # combined of h, l , s\n",
    "            combined_hls = hls_combine(undist_img, th_h, th_l, th_s)\n",
    "            #cv2.imshow('HLS combined image', combined_hls)\n",
    "           \n",
    "            \n",
    "            # the combination of the two approaches\n",
    "            combined_result = comb_result(combined_gradient, combined_hls)\n",
    "            #cv2.imshow('combined image', combined_result)\n",
    "          \n",
    "            \n",
    "           # get the wrap image \n",
    "            c_rows, c_cols = combined_result.shape[:2]\n",
    "            \n",
    "            s_LTop2, s_RTop2 = [c_cols / 2 - 24, 5], [c_cols / 2 + 24, 5]\n",
    "            s_LBot2, s_RBot2 = [110, c_rows], [c_cols - 110, c_rows]\n",
    "\n",
    "            src = np.float32([s_LBot2, s_LTop2, s_RTop2, s_RBot2])\n",
    "            dst = np.float32([(170, 720), (170, 0), (550, 0), (550, 720)])\n",
    "\n",
    "            warp_img, M, Minv = warp_image( combined_gradient, src, dst, (720, 720))\n",
    "            #cv2.imshow('warp', warp_img)\n",
    "            \n",
    "\n",
    "            # decide if line is detected or not\n",
    "            searching_img = find_LR_lines(warp_img, left_line, right_line)\n",
    "            #cv2.imshow('LR searching', searching_img)\n",
    "            \n",
    "            \n",
    "            # draw lane on prespective view\n",
    "            w_comb_result, w_color_result = draw_lane(searching_img, left_line, right_line)\n",
    "            #cv2.imshow('w_comb_result', w_comb_result)\n",
    "           \n",
    "\n",
    "            # Drawing the lines back down onto the road after croping the above\n",
    "            color_result = cv2.warpPerspective(w_color_result, Minv, (c_cols, c_rows))\n",
    "            lane_color = np.zeros_like(undist_img)\n",
    "            lane_color[220:rows - 12, 0:cols] = color_result\n",
    "\n",
    "                # Combine the result with the original image\n",
    "            result = cv2.addWeighted(undist_img, 1, lane_color, 0.3, 0)\n",
    "            #cv2.imshow('result', result.astype(np.uint8))\n",
    "\n",
    "            info =  np.zeros_like(result)\n",
    "            info[5:110, 5:190] = (255, 255, 255)\n",
    "\n",
    "            info = cv2.addWeighted(result, 1, info, 0.2, 0)\n",
    "\n",
    "\n",
    "            info = print_road_status(info, left_line, right_line)\n",
    "            #cv2.imshow('road info', info)\n",
    "           \n",
    "            #out.write(frame)\n",
    "            combined_gradient = cv2.resize(combined_gradient,(0,0),None,0.7,4)\n",
    "            combined_hls      = cv2.resize(combined_hls,(0,0),None,0.7,4)\n",
    "            combined_result   = cv2.resize(combined_result,(0,0),None,0.7,4)\n",
    "            # warp_img   = cv2.resize(warp_img,(0,0),None,0.5,0.5)\n",
    "            \n",
    "            searching_img = cv2.resize(searching_img,(0,0),None,0.8,0.8)\n",
    "            w_comb_result = cv2.resize(w_comb_result,(0,0),None,0.8,0.8)\n",
    "            \n",
    "            \n",
    "            \n",
    "            hoz1 = np.hstack((combined_gradient,combined_hls,combined_result))\n",
    "            hoz2 = np.hstack((searching_img,w_comb_result))\n",
    "            \n",
    "            \n",
    "            #,searching_img,w_comb_result\n",
    "            #vec = np.vstack(hoz,info)\n",
    "            cv2.imshow('gradient_combined_________combined_hls_________combined_result',hoz1)\n",
    "            cv2.imshow('lane_with_prespective______without lane______with lane',hoz2)\n",
    "            cv2.imshow('wrap',warp_img)\n",
    "            cv2.imshow('final_image',info)\n",
    "            \n",
    "            \n",
    "            #print(combined_gradient.shape,combined_hls.shape,combined_result.shape,warp_img.shape,searching_img.shape,w_comb_result.shape,info.shape)\n",
    "            \n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "            final.append(info)   \n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b6f1bc-7ec7-4684-b16a-97e591cc9baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19bf255b-f96e-4f1d-acb8-2679e578ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image(path, img):\n",
    "    # img = img*(2**16-1)\n",
    "    # img = img.astype(np.uint16)\n",
    "    # img = img.astype(np.uint8)\n",
    "    img = cv2.convertScaleAbs(img, alpha=(255.0))\n",
    "    cv2.imwrite(path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e735b15-01a6-4bee-bde0-7a09d80ad658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f15877-5e61-4083-972d-77f8210e5c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"data5\"):\n",
    "    os.makedirs('data5')\n",
    "for i in range(len(final)):\n",
    "    name = './data5/frame'+ \"\"+str(i)+ '.jpg'\n",
    "    cv2.imwrite(name,final[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f2d5a3d-6bdd-402f-8220-7e72f4e265a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "img_array = []\n",
    "i = 0\n",
    "#for filename in glob.glob(\"data5/frame\"+ \"\"+str(i)+\".jpg\"):\n",
    "for i in range(len(final)):\n",
    "    img = cv2.imread(\"data5/frame\"+ \"\"+str(i)+\".jpg\")\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('project2.avi',cv2.VideoWriter_fourcc(*'DIVX'), 25 , size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1534934-4da4-417e-b170-21d41b396c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img , title, cmap_type=\"gray\" ):\n",
    "    plt.figure(figsize=(13,13))\n",
    "    plt.title(title)\n",
    "    plt.imshow(img,cmap_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72ef2c04-5b33-4536-8f2c-6a837d32a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_show(final[148] ,\"gfgdkfjgdkjglkdjf\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e86ecf-ef0d-4174-9bca-87ea21b8880a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b46ac-f098-407f-aca6-12ef65c63220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33da22d8-930d-4acf-a8cd-d130ee424387",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Yolo Object Detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ca63d-d387-4d83-9945-fc66abcac793",
   "metadata": {},
   "source": [
    "### import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a662d354-8070-4ebd-8ee2-8641013656bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd5c18-d947-4042-90cd-c6d5bd8e7511",
   "metadata": {},
   "source": [
    "### load yolo weights and cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d7155f-0fb1-4b4d-97f6-6c5de25b24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = os.path.join(\"yolo\",\"yolov3.cfg.txt\")\n",
    "weight_path = os.path.join(\"yolo\",\"yolov3.weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3977fe0-3843-4b16-82f5-53fb68e438a3",
   "metadata": {},
   "source": [
    "### load the neural net in cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecfa2efc-882d-418c-bf2d-f632d68fa08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet(cfg_path,weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc18bc4-b57d-46eb-aaf6-e4bc794f3358",
   "metadata": {},
   "source": [
    "### get Layers Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8790f534-3038-4031-be9f-c554187bc020",
   "metadata": {},
   "outputs": [],
   "source": [
    "names =net.getLayerNames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78964e-0ea6-422e-bb92-be843edf5a29",
   "metadata": {},
   "source": [
    "### load the test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e63a169-2af6-484f-8a1f-71934f3a4d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Read the video from specified path\n",
    "cam = cv2.VideoCapture(\"project_video.mp4\")\n",
    "\n",
    "try:\n",
    "\t\n",
    "\t# creating a folder named data\n",
    "\tif not os.path.exists('data'):\n",
    "\t\tos.makedirs('data')\n",
    "\n",
    "# if not created then raise error\n",
    "except OSError:\n",
    "\tprint ('Error: Creating directory of data')\n",
    "\n",
    "# frame\n",
    "currentframe = 0\n",
    "\n",
    "while(True):\n",
    "\t\n",
    "\t# reading from frame\n",
    "\tret,frame = cam.read()\n",
    "\n",
    "\tif ret:\n",
    "\t\t# if video is still left continue creating images\n",
    "\t\tname = './data/frame' + str(currentframe) + '.jpg'\n",
    "\n",
    "\n",
    "\t\t# writing the extracted images\n",
    "\t\tcv2.imwrite(name, frame)\n",
    "\n",
    "\t\t# increasing counter so that it will\n",
    "\t\t# show how many frames are created\n",
    "\t\tcurrentframe += 1\n",
    "\telse:\n",
    "\t\tbreak\n",
    "        \n",
    "\n",
    "# Release all space and windows once done\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319572ca-1017-4830-9aab-139d7b173847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94854b53-853a-4ad0-85ce-5c9276b6d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Frames = []\n",
    "for i in range(0,currentframe,5):\n",
    "    img = cv2.imread(\"data/frame\"+ \"\"+str(i)+\".jpg\")\n",
    "    img= cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    Frames.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aee2615-c337-433c-8f46-834dc7b69590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(Frames[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bca205-0748-4ff9-a83e-86c2c27eebb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bca937b4-8447-49ce-bde3-94a92912d9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yolo_82', 'yolo_94', 'yolo_106']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(H,W)=Frames[20].shape[:2]\n",
    "layers_names =[names[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "layers_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b68ac-95f9-4220-8d5a-a0e197cbf77d",
   "metadata": {},
   "source": [
    "### run the interface on the test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31f43202-b88b-4425-90fc-550f39e50f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = os.path.join(\"yolo\",\"coco.names.txt\")\n",
    "labels=open (labels_path).read().strip().split(\"\\n\")\n",
    "labels=np.array(labels)\n",
    "labels=labels[1:8]\n",
    "\n",
    "for j in range(len(Frames)):\n",
    "    boxes =[]\n",
    "    confidences=[]\n",
    "    classIDs=[]\n",
    "    x_bef , y_bef  , w_bef , h_bef  = 0 , 0 , 1 , 1\n",
    "    \n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(Frames[j], 1/255.0, (416,416), crop=False, swapRB=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    #cal the time of our algo\n",
    "    start_t =time.time()\n",
    "    layers_output =net.forward(layers_names)\n",
    "       \n",
    "    \n",
    "    for output in layers_output:\n",
    "        for dection in output:\n",
    "            scores = dection[6:13]\n",
    "            classID =np.argmax(scores)\n",
    "            confidence=scores[classID]\n",
    "\n",
    "            if confidence> 0.5 :\n",
    "                box = dection[:4] * np.array([W,H,W,H])\n",
    "                bx,by,bw,bh= box.astype(\"int\")\n",
    "\n",
    "                x=int(bx-(bw/2))\n",
    "                y=int(by-(bh/2))\n",
    "\n",
    "\n",
    "                boxes.append([x,y,int(bw),int(bh)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "                \n",
    "                \n",
    "    \n",
    "    \n",
    "    idxs =cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.4)\n",
    "    if len(idxs) > 0:\n",
    "    \n",
    "        for i in idxs.flatten():\n",
    "            (x,y)=[boxes[i][0],boxes[i][1]]\n",
    "            (w,h)=[boxes[i][2],boxes[i][3]]\n",
    "            \n",
    "            '''\n",
    "            dx = min(x+w, x_bef+w_bef) - max(x, x_bef)\n",
    "            dy = min(y+h,y_bef+h_bef) - max(y, y_bef)\n",
    "            if (dx>=0) and (dy>=0):\n",
    "                intersection =  dx*dy\n",
    "            else:\n",
    "                intersection = 0\n",
    "            #print(j,\" \",intersection/(w*h) ,x ,\" \",y,\" \",w,\" \",h,\" \",x_bef ,\" \",y_bef,\" \",w_bef,\" \",h_bef)\n",
    "            if((w <= 1000) and ((intersection/(w*h))< 0.75)):\n",
    "               '''\n",
    "            if(w<=1000):\n",
    "                cv2.rectangle(Frames[j],(x,y),(x+w,y+h),(0,255,255),2)\n",
    "                cv2.putText(Frames[j],\"{}\"\":\" \"{}\".format(labels[classIDs[i]], str(round(confidences[i], 3))),(x,y-5),cv2.FONT_HERSHEY_PLAIN,1.5,(0,139,139),2)\n",
    "                x_bef , y_bef  , w_bef , h_bef  = x , y , w , h  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530d086b-a6e9-4b00-82c4-550bd8d7a44f",
   "metadata": {},
   "source": [
    "### plot the bounding boxes in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67cb5da8-9160-47a5-a38c-5f49435a61ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imshow(\"image\",cv2.cvtColor(Frames[50],cv2.COLOR_BGR2RGB))\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e46090c-1dbf-4061-94fa-d26d4be8bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"data6\"):\n",
    "    os.makedirs('data6')\n",
    "for i in range(len(Frames)):\n",
    "    Frames[i]= cv2.cvtColor(Frames[i],cv2.COLOR_BGR2RGB)\n",
    "    name = './data6/frame'+ \"\"+str(i)+ '.jpg'\n",
    "    cv2.imwrite(name,Frames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d92cb3f-2cbb-41c4-b617-08b006465db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "img_array = []\n",
    "i = 0\n",
    "#for filename in glob.glob(\"data5/frame\"+ \"\"+str(i)+\".jpg\"):\n",
    "for i in range(len(Frames)):\n",
    "    img = cv2.imread(\"data6/frame\"+ \"\"+str(i)+\".jpg\")\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('project6.avi',cv2.VideoWriter_fourcc(*'DIVX'), 5 , size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d22a27e-e4d3-4846-a253-a7eb6b3bc8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
